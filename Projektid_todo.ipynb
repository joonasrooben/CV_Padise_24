{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padise 2024\n",
    "## Masinnägemise töötuba\n",
    "Koostanud: Joonas Järve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valige endale huvipakkuv ülesanne, mida lahendada ning probleemide korral guugeldage või küsige juhendajalt või kaasõpilastelt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erinevad ülesanded on erineva raskusastmega, kuid kõik jälgivad sama põhimõtet: \n",
    "\n",
    "1. ülesande lahendab **MUDEL** \n",
    "2. mudeli tööd demonstreerib **veebikaamera liides**\n",
    "\n",
    "Siin on antud üldine veebikaamera liidese tsükkel ning sinna sisse tuleb tavaliselt panna mudel, mis töötleb pilte ja tagastab tulemuse veebikaamera väljundisse i.e ekraanile :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, sys, numpy, os \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0) #alustab veebikaamera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() #loeb sisse kaadri kaamerast\n",
    "    if not ret: #kontrollib et midagi ei läinud valesti\n",
    "        break\n",
    "    ##\n",
    "    ##\n",
    "    ##Siin saab teha kaadritöötlust ja lisada masinnägemise MUDELi \n",
    "    ##\n",
    "    ##\n",
    "    cv2.imshow('Väljund', frame) #kuvab pildi veebikaamera väljundisse\n",
    "\n",
    "    # Programm lõpeb, kui vajutame 'q' \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Lõpetuseks vabastame kaamera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. variant : Näotuvastus  \n",
    "(kood on suures osas pärit siit : https://www.geeksforgeeks.org/face-detection-using-python-and-opencv-with-webcam/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgnev koodilõik on andmetekogumiseks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_file = './naotuvastus/haarcascade_frontalface_default.xml' #mudeli asukoht\n",
    "datasets = './naotuvastus/datasets' #näopiltide asukoht\n",
    "\n",
    "sub_data = 'Minu Nimi'\t# kaust minu näo piltidest (muuda vastavalt)\n",
    "\n",
    "# Kontrolli, kas kaust on olemas; kui ei, siis loo see\n",
    "path = os.path.join(datasets, sub_data) \n",
    "if not os.path.isdir(path): \n",
    "\tos.mkdir(path) \n",
    "\n",
    "# pildi suurus\n",
    "(width, height) = (130, 100)\t \n",
    "\n",
    "#'0' on veebikaamera tüüpiliselt, \n",
    "# kui on probleeme proovi '1'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file) #laeme mudeli \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# See koodijupp teeb veebikaameraga ühe pildi ja kasutab seda hiljem teie ära tundmiseks \n",
    "count = 1\n",
    "#to-do1: teha see osa ümber nii, et programm koguks etteantud x arvu pilte \n",
    "#to-do2: nõua, et iga järgev pilt oleks eelnevast piisavalt erinev (kasutada nt. eukleidilist kaugust vms.)\n",
    "# või tehakse mingi aja tagant\n",
    "\n",
    "ret, frame = cap.read()\n",
    "    # Muuda pilt halltoonideks paremaks näotuvastuseks\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 4) # Tuvasta näod pildil\n",
    "for (x, y, w, h) in faces: \n",
    "\t# Joonista ruut näo ümber\n",
    "\tcv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "\t# Võta näo osa, muuda suurust ja salvesta\n",
    "\tface = gray[y:y + h, x:x + w] \n",
    "\tface_resize = cv2.resize(face, (width, height)) \n",
    "\tcv2.imwrite('% s/% s.png' % (path, count), face_resize) \n",
    "\n",
    "\n",
    "# Näita pilti koos näo ruuduga\n",
    "cv2.imshow('OpenCV', frame) \n",
    "\n",
    "# Lõpetuseks vabastame kaamera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teine osa treenib mudeli tehtud fotode põhjal ja tuvastab näo ja kuvab kui enesekindel mudel on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing Face Please Be in sufficient Lights...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = 4\n",
    "\n",
    "# Tuvastame näo\n",
    "print('Recognizing Face Please Be in sufficient Lights...') \n",
    "\n",
    "# Loome piltide järjendi ja vastavate nimede järjendi \n",
    "(images, labels, names, id) = ([], [], {}, 0) \n",
    "for (subdirs, dirs, files) in os.walk(datasets): \n",
    "\tfor subdir in dirs: \n",
    "\t\tnames[id] = subdir \n",
    "\t\tsubjectpath = os.path.join(datasets, subdir) \n",
    "\t\tfor filename in os.listdir(subjectpath): \n",
    "\t\t\tpath = subjectpath + '/' + filename \n",
    "\t\t\tlabel = id\n",
    "\t\t\timages.append(cv2.imread(path, 0)) \n",
    "\t\t\tlabels.append(int(label)) \n",
    "\t\tid += 1\n",
    "(width, height) = (130, 100) \n",
    "\n",
    "# Create a Numpy array from the two lists above \n",
    "(images, labels) = [numpy.array(lis) for lis in [images, labels]] \n",
    "\n",
    "# OpenCV treenib kogutud fotode pealt mudeli\n",
    "# NOTE FOR OpenCV2: remove '.face' \n",
    "model = cv2.face.LBPHFaceRecognizer_create() \n",
    "model.train(images, labels) \n",
    "\n",
    "# Kasutame fisherRecognizer mudelit veebikaameraga \n",
    "face_cascade = cv2.CascadeClassifier(haar_file) \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\tret, frame = cap.read()\n",
    "\tif ret == False:\n",
    "\t\tbreak\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\tfaces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "\tfor (x, y, w, h) in faces: \n",
    "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "\t\tface = gray[y:y + h, x:x + w] \n",
    "\t\tface_resize = cv2.resize(face, (width, height)) \n",
    "\t\t# Proovib nägu tuvastada\n",
    "\t\tprediction = model.predict(face_resize) \n",
    "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3) \n",
    "\n",
    "\t\tif prediction[1]<500: \n",
    "\n",
    "\t\t\tcv2.putText(frame, '% s - %.0f' %\n",
    "\t\t\t    (names[prediction[0]], prediction[1]), (x-10, y-10), \n",
    "\t\t\t   cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n",
    "\t\telse: \n",
    "\t\t\tcv2.putText(frame, 'tundmatu',(x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n",
    "\n",
    "\tcv2.imshow('OpenCV', frame) \n",
    "\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\t\tbreak\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Proovige tuvastajate erinevates tingimustes (pime, hämar, profiil jne.)**\n",
    "2. **Proovige lisada ka kaaslaste nägusid ja treenida nende pealt rohkemate nägude tuvastaja**\n",
    "3. **Proovige lahendada to-do1 ja to-do2 ning vaadake, kas programm läheb paremaks** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do 1 vihjed: Muuda programmi nii, et see koguks määratud arvu pilte.\n",
    "1. *Defineeri muutuja*: Määra piltide arv, mida soovid koguda, näiteks `x = 30`. Seejärel asenda `while` tsükli tingimus `count < 30` selle muutujaga.\n",
    "2. *Näide*:\n",
    "   ```python\n",
    "   x = 50  # Näiteks kui soovid koguda 50 pilti\n",
    "   while count < x:\n",
    "   ```\n",
    "\n",
    "To-do 2: Nõua, et iga järgnev pilt oleks eelnevast piisavalt erinev.\n",
    "1. *Salvesta eelmine pilt*: Hoia viimase salvestatud pildi koopiat, et võrrelda seda järgmise pildiga.\n",
    "2. *Kasuta eukleidilist kaugust*: Arvuta eukleidiline kaugust kahe järjestikuse pildi vahel, kasutades pildi pikslite väärtusi (või eile arutatud *Linear Binary Pattern Histogram*). Võrdle seda mingi eelnevalt määratud lävendiga, et otsustada, kas salvestada järgmine pilt.\n",
    "\n",
    "Näiteks, Eukleidiline kaugus kahe punkti $ \\mathbf{p} $ ja $ \\mathbf{q} $ vahel $ \\mathbb{R}^n$ ruumis arvutatakse järgneva valemi järgi:\n",
    "\n",
    "$$ \n",
    "d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
    "$$\n",
    "\n",
    "See valem näitab, et eukleidiline kaugus on punktide koordinaatide erinevuste ruutude summa ruutjuur.\n",
    "\n",
    "3. *Pildi vektoriks teisendamine*: Teisenda pilt vektoriks (nt kasutades `.flatten()` meetodit numpy's), mis teeb kauguse arvutamise lihtsamaks.\n",
    "4. *Näide*:\n",
    "   ```python\n",
    "   import numpy as np\n",
    "   threshold = 1000  # Määra eukleidilise kauguse lävi\n",
    "   last_face = None  # Salvesta viimane näopilt\n",
    "\n",
    "   for (x, y, w, h) in faces:\n",
    "       face = gray[y:y + h, x:x + w]\n",
    "       face_resize = cv2.resize(face, (width, height))\n",
    "       current_face = np.array(face_resize).flatten()\n",
    "\n",
    "       if last_face is not None:\n",
    "           distance = np.linalg.norm(current_face - last_face)\n",
    "           if distance < threshold:\n",
    "               continue  # Jäta see pilt vahele, kui see on liiga sarnane eelmisega\n",
    "\n",
    "       last_face = current_face  # Uuenda viimast pilti\n",
    "       cv2.imwrite('%s/%s.png' % (path, count), face_resize)\n",
    "       count += 1\n",
    "   ```\n",
    "\n",
    "Lisaks:\n",
    "- *Aja järgi salvestamine*: Kui soovid pilte salvestada kindlate ajavahemike järel, võiksid kasutada ajafunktsioone (nt `time.sleep(sec)`).\n",
    "\n",
    "Üldine nõuanne:\n",
    "- *Testi ja kohanda lävend*: Eukleidilise kauguse lävendi valimisel võib osutuda vajalikuks katsetamine ja kohandamine, sõltuvalt konkreetsest rakendusest ja kaamerast saadud pildi kvaliteedist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. variant: Dinomäng käežestidega\n",
    "\n",
    "Et mängida `chrome://dino/` mängu käežestidega, siis võiks selleks kasutada kolme paketti:`opencv`, `mediapipe` ja `pyautogui`. \n",
    "\n",
    "1. **OpenCV veebikaamera tsükkel on antud töövihiku päises** \n",
    "2. **Lisa sinna juurde `mediapipega` käetuvastus** vt (https://mediapipe.readthedocs.io/en/latest/solutions/hands.html)\n",
    "3. **Kui käsi on tuvastatud, siis lisa õige žesti juurde** `pyautogui` käsk, mis vajutab `space`'i\n",
    "```\n",
    "#Pane Dino hüppama\n",
    "pyautogui.press('space')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kasi.webp\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import pyautogui\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_thumbs_up(hand_landmarks):\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    # Kontrolli kas pöial on kõrgemal kui nimetissõrm\n",
    "    return thumb_tip.y < index_finger_tip.y\n",
    "\n",
    "mp_hands = mp.solutions.hands #defineerib käed\n",
    "hands = mp_hands.Hands( #defineerib, mitu kätt tuvastab, ning tuvastuskindluse\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils #defineerib käe skeletoni joonistaja\n",
    "\n",
    "capture = cv2.VideoCapture(0) #alustab veebikaamera\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640) #madaladab veebikaamera kvaliteeti\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "## Siit alates tuleb lisada juurde punktid 1 - 3\n",
    "##\n",
    "##\n",
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. variant: Koloriseeri (žesti peale)\n",
    "<img src=\"./bw-to-color.jpg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "(kood: https://www.geeksforgeeks.org/black-and-white-image-colorization-with-opencv-and-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antud on kolorisaator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from cv2 import dnn\n",
    "\n",
    "#--------Mudelifailide asukohad--------#\n",
    "proto_file = './colorization/colorization_deploy_v2.prototxt'  # Prototxt-fail, mis defineerib mudeli kihtide struktuuri\n",
    "model_file = './colorization/colorization_release_v2.caffemodel'  # Treenitud mudeli fail\n",
    "hull_pts = 'colorization/pts_in_hull.npy'  \n",
    "img_path = 'minbw.jpg'  # Mustvalge pildi asukoht\n",
    "#--------------#--------------#\n",
    "\n",
    "#--------Loeme mudeli parameetrid--------#\n",
    "net = dnn.readNetFromCaffe(proto_file, model_file)  # Laadime mudeli Caffe formaadis\n",
    "kernel = np.load(hull_pts)  # Laadime klastrikeskpunktid\n",
    "#-----------------------------------#---------------------#\n",
    "\n",
    "#-----Loeme sisse ja eeltöötleme pildi --------#\n",
    "img = cv2.imread(img_path)  # Laadime pildi\n",
    "scaled = img.astype(\"float32\") / 255.0  # Skaleerime piksliväärtused vahemikku 0..1\n",
    "lab_img = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)  # Teisendame pildi LAB värviruumi\n",
    "#-----------------------------------#---------------------#\n",
    "\n",
    "# Lisame mudelile klasterkeskmed 1x1 konvolutsioonidena\n",
    "class8 = net.getLayerId(\"class8_ab\")  # Leiame kihi ID\n",
    "conv8 = net.getLayerId(\"conv8_313_rh\")\n",
    "pts = kernel.transpose().reshape(2, 313, 1, 1)  # Teisendame ja kujundame klastri keskpunktid sobivaks\n",
    "net.getLayer(class8).blobs = [pts.astype(\"float32\")]  # Määrame kihi parameetrid\n",
    "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]  # Määrame kihi parameetrid\n",
    "#-----------------------------------#---------------------#\n",
    "\n",
    "# Muudame pildi suurust vastavalt võrgu nõuetele\n",
    "resized = cv2.resize(lab_img, (224, 224))  # Muudame pildi suurust\n",
    "# Eraldame L kanali\n",
    "L = cv2.split(resized)[0]  # Eraldame Luminance kanali\n",
    "# L kanalilt lahutame keskmise\n",
    "L -= 50  # Keskmise lahutamine\n",
    "#-----------------------------------#---------------------#\n",
    "\n",
    "# Prognoosime ab kanaleid sisendiks olevast L kanalist\n",
    "net.setInput(cv2.dnn.blobFromImage(L))  # Seadistame sisendi\n",
    "ab_channel = net.forward()[0, :, :, :].transpose((1, 2, 0))  # Saame tulemused ja teisendame need sobivaks\n",
    "# Suurendame prognoositud 'ab' mahtu sama suureks kui meie sisendpilt\n",
    "ab_channel = cv2.resize(ab_channel, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# Võtame pildilt L kanali\n",
    "L = cv2.split(lab_img)[0]\n",
    "# Ühendame L kanali prognoositud ab kanaliga\n",
    "colorized = np.concatenate((L[:, :, np.newaxis], ab_channel), axis=2)\n",
    "\n",
    "# Teisendame pildi tagasi BGR värviruumi\n",
    "colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
    "colorized = np.clip(colorized, 0, 1)  # Piirame väärtused vahemikku 0..1\n",
    "\n",
    "# Muudame pildi väärtused vahemikku 0-255 ja teisendame need täisarvuliseks\n",
    "colorized = (255 * colorized).astype(\"uint8\")\n",
    "\n",
    "# Muudame piltide suurusi ja kuvame need kõrvuti\n",
    "img = cv2.resize(img,(640,640))\n",
    "colorized = cv2.resize(colorized,(640,640))\n",
    "\n",
    "result = cv2.hconcat([img, colorized])  # Kombineerime pildid kõrvuti\n",
    "\n",
    "cv2.imshow(\"Grayscale -> Colour\", result)  # Kuvame tulemuse\n",
    "\n",
    "cv2.waitKey(0)  # Ootame kasutajalt käsku pildi sulgemiseks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Proovige esmalt koloriseerijat mõne enda pildi peal**\n",
    "2. **Tehke veebikaamera mustvalgeks ja siis koloriseerige *live* pilti**\n",
    "\n",
    "vihjed: \n",
    "* *Kasutage* faili päises olevat veebikaamera tsükklit ning lisage koloriseerija vastavalt sinna sisse (ainult mingi osa koloriseerija koodist tuleb sinna panna, mitte kõike, muidu on kaamera liiga aeglane hiljem)\n",
    "* *Kaadrite saamine kaamerast*:\n",
    "    - `capture.read()` kasutamine tagab, et saame kaamerast järgmise kaadri. `ret` on tõeväärtus (True/False), mis näitab, kas kaadri lugemine õnnestus.\n",
    "   \n",
    "    ```python\n",
    "    ret, frame = capture.read()  # Loeb kaamera järgmise kaadri\n",
    "    ```\n",
    "\n",
    "* *Kaadri teisendamine halliks ja tagasi BGR-iks*:\n",
    "    - Esimeses etapis peaks teisendama värvilise veebikaamera BGR kaadri halltoonideks (`cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)`).\n",
    "    - Seejärel teisendama halltoonides kaader tagasi BGR formaati (`cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)`), et säilitada kolmekanaliline struktuur, mis on vajalik edasisteks operatsioonideks.\n",
    "    \n",
    "\n",
    "* *Kaadri skaleerimine ja ettevalmistamine värviliseks muutmiseks*:\n",
    "    - Skaleerimine, (`frame.astype(\"float32\") / 255.0`), et normaliseerida pikslite väärtused vahemikku 0 kuni 1. See aitab parandada mudeli töödeldavust ja vähendada andmete varieeruvust.\n",
    "    - Teisendada see edasi LAB värviruumi.\n",
    "\n",
    "    ```python\n",
    "    scaled = frame.astype(\"float32\") / 255.0  # Normaliseeri pikslite väärtused\n",
    "    gray_img = cv2.cvtColor(scaled, cv2.COLOR_BGR2GRAY)  # Teisenda skaalitud kaader halltoonideks\n",
    "    bgr_from_gray = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)  # Teisenda halltoonides kaader tagasi BGR formaati\n",
    "    lab_img = cv2.cvtColor(bgr_from_gray, cv2.COLOR_BGR2LAB)  # Teisenda BGR kaader LAB värviruumi\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Lisage mustvalge, koloriseeritud ja originaalne režiim žesti peale**\n",
    "\n",
    "*Lisa sinna juurde `mediapipega` käetuvastus* vt (https://mediapipe.readthedocs.io/en/latest/solutions/hands.html)\n",
    "Abiks: on Variant 2 alguses antud kood.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padise_laager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
