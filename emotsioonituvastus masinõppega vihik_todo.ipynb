{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masinnägemise töötuba Padisel 2024\n",
    "## Masinõppega emotsioonituvastus; koodivihik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seekord püüame pildi pealt tuvastada emotsioone. Treeningandmetena kasutame FER2013 andmestiku (https://www.kaggle.com/datasets/nicolejyt/facialexpressionrecognition). Andmestik koosneb 34034 näopildist ja 7 emotsioonist. Vt. Näide:\n",
    "<img src=\"./fer_sample.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defineerime andmestiku ja loeme selle sisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loome ise FER2013 andmestiku\n",
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data_frame.iloc[idx]\n",
    "        image = np.array([int(pixel) for pixel in row['pixels'].split()]).reshape(48, 48).astype(np.uint8)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        label = int(row['emotion'])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Laeme FER2013 andmestiku sisse\n",
    "def load_fer2013_data(csv_file, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    dataset = FER2013Dataset(csv_file=csv_file, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faili asukoht \n",
    "csv_file = './fer2013/fer2013.csv'  # uuenda endale vastavalt\n",
    "train_loader, test_loader = load_fer2013_data(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defineerime nüüd keerukama mudeli, mis kasutab ka **konvolutsioonilisi kihte** (e.g `Conv2d`). Sellised kihid on eriti head piltide jaoks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defineerime mudeli emotsioonide tuvastamiseks\n",
    "def create_emotion_recognition_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3, padding=1), #Konvolutsioon\n",
    "        nn.ReLU(), #aktivatsioon\n",
    "        nn.MaxPool2d(2, 2), #agregaator\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128 * 6 * 6, 64), #Perceptron pmst\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 7),\n",
    "        nn.LogSoftmax(dim=1) #kaofunktsioon\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# mudeli treenimise tsükkel\n",
    "def train_model(model, train_loader, test_loader, num_epochs=10):\n",
    "    criterion = nn.NLLLoss() #kaofunktsioon ehk õppimise headuse mõõt/suunis\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) #õpialgoritm\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epohh {epoch+1}, Kadu: {total_loss / len(train_loader)}')\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test täpsus: {accuracy}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_emotion_recognition_model() #defineerib mudeli\n",
    "trained_model = train_model(model, train_loader, test_loader) #treenib mudeli\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proovime mudelit test andmetega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def predict_random_test_image(model, test_loader):\n",
    "    # Võtab juhuslikult ühe test andmepunkti ning ennustab selle numbrit\n",
    "    test_images, test_labels = next(iter(test_loader))\n",
    "    idx = random.randint(0, len(test_images) - 1)\n",
    "    image, label = test_images[idx], test_labels[idx]\n",
    "    \n",
    "    # ennustab mudelist\n",
    "    output = model(image.unsqueeze(0))  \n",
    "    _, predicted = torch.max(output, 1)\n",
    "    enesekindlus = np.round(np.e**torch.max(output,1)[0].item(),3)\n",
    "    \n",
    "    # Defineerime emotsioonid\n",
    "    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "    # Kuvame tulemuse\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  \n",
    "    plt.title(f'Õige emotsioon: {emotions[label]}, Ennustatud emotsioon: {emotions[predicted.item()]}, Enesekindlus: {enesekindlus}')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_random_test_image(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nüüd, loome veebikaamera rakenduse, mis lisab meie kaamerapildile meie emotsiooni.\n",
    "\n",
    "vihjed:\n",
    "1. kasutage `cv2` teeki ja dokumentatsiooni (https://docs.opencv.org/4.x/d7/dbd/group__imgproc.html)\n",
    "2. ennustamine on juba ette antud funktsioonis `predict_random_test_image`\n",
    "3. pildi peab muutma mustvalgeks ning suuruse ümber skaleerima\n",
    "4. lisage ka mudeli enesekindlus \n",
    "5. isikupärastage veel lisaks kuidas soovite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_webcam(model ):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # muuda pilt BGR värviskaalast mustvalgeks GRAY\n",
    "        gray = ... #todo\n",
    "        # reskaleeri pilt sobivaks mudeli jaoks\n",
    "        resized = ... #todo\n",
    "        tensor = torch.tensor(resized).unsqueeze(0).unsqueeze(0).float().to(\"cpu\") / 255.0\n",
    "\n",
    "        # Ennustus\n",
    "        with torch.no_grad():\n",
    "            outputs = ... #todo: ennusta\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted_emotion = emotions[predicted.item()]\n",
    "\n",
    "        # Kuva tulemus tekstina\n",
    "        cv2.putText(...) #todo\n",
    "        \n",
    "        cv2.imshow('Emotsiooni tuvastus', frame)\n",
    "\n",
    "        # Programm lõpeb, kui vajutame 'q' \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Lõpetuseks vabastame kaamera\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_webcam(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS** \n",
    "\n",
    "Kui tundub, et mudel ei saa meie enda numbritest aru, siis proovige mudelit paremaks saada lisades või eemaldades `create_emotion_recognition_model()` funktsiooni kihte, muutes aktivatsioone või regularisatsiooni või varieerides treeningu pikkust ehk epohhe. Vt. PyTorch dokumentatsiooni (https://pytorch.org/docs/stable/nn.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padise_laager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
